---
title: "p8105_hw6_LG2982"
author: "Lizbeth Gomez"
date: "11/22/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(modelr)
library(mgcv)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_bw() + theme(legend.position = "bottom"))

```

# Data import and cleaning:
  - Load and clean the data for regression analysis:

```{r}
birth = read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = recode(babysex, 
                          "1" = "Male",
                          "2" = "Female"),
         fincome = fincome * 100,
         frace = recode(frace,
                        "1" = "White",
                        "2" = "Black",
                        "3" = "Asian",
                        "4" = "Puetro Rican",
                        "8" = "Other",
                        "9" = "Unknown"),
         malform = recode(malform, 
                          "0" = "Yes",
                          "1" = "No"
                          ),
         mrace = recode(mrace,
                        "1" = "White",
                        "2" = "Black",
                        "3" = "Asian",
                        "4" = "Puetro Rican",
                        "8" = "Other")
         ) 
sum(is.na(birth))
```
 *There are no missing values in this dataset*
 
  - Propose a regression model for birthweight. To start, I will look at all variables that are known to underly birthweight outcomes.
```{r}
model_1 = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birth) 

summary(model_1)

birth %>%
  modelr::add_residuals(model_1) %>%
  modelr::add_predictions(model_1) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_violin() +
  geom_hline(yintercept = 0, color = "peru")

```

*As shown in this plot of residuals versus predicted values, there is reasonable cosntant variace in the data as most of the observations fall fall around 0. (the very low and very high observations can be outliers)*

- Comparison models:

```{r}
model_2 = lm(bwt ~ blength + gaweeks, data = birth)
model_3 = lm(bwt ~ (bhead + blength + babysex)^3, data = birth)


```

```{r}
crossv_mc(birth, 100)  %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
    mutate(model_1  = map(train, 
                     ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
                           gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
         
         model_2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         
         model_3 = map(train, ~lm(bwt ~ (bhead + blength + babysex)^3, data = .x))
         )%>%
  mutate(rmse_model1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y))) %>%
    select(starts_with("rmse")) %>% 
  pivot_longer(
      everything(),
      names_to = "model", 
      values_to = "rmse",
      names_prefix = "rmse_") %>% 
    mutate(model = fct_inorder(model)) %>% 
    ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```

*Based on the plot, we see that model 1 has the lowest RMSE, so we conclude that it fits the data better than model 2 and model 3*